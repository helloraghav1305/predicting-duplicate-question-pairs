{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c7b7c395-82fe-4f2b-9454-43af7f3594c0",
    "_uuid": "9db29bbb-f55f-45c1-b892-f6ed1f38c985",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Predicting Duplicate Question Pairs with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "894821fb-57e6-4516-8794-965007d9d51f",
    "_uuid": "caea9014-156a-4948-9ec3-fdbd47dc5a80",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Inspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "76fe361d-cfcf-4516-9b81-c4270bc52c12",
    "_uuid": "ca63cb40-2d32-4de5-92fb-f621d9e03f2f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "This notebook is inspired from the ['Getting Started with NLP for absolute beginners'](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners) notebook by Jeremy Howard. It focuses on comparing two short phrases and assigning a similarity score. \n",
    "\n",
    "\n",
    "    A score closer to 0 means the words/phrases have very different meanings\n",
    "    A score closer to 1 means the phrases have similar meanings.\n",
    "\n",
    "\n",
    "Key highlights from the above Notebook:\n",
    "\n",
    "1. Creating a Combined Input Feature\n",
    "\n",
    "    To compare two text columns in the context of a third, the notebook demonstrates how to combine them into a single input string.\n",
    "    For example, if our dataset has three columns — col1, col2, and col3 — and we want to compare col1 and col2 based on the context in col3, we can format the input like this:\n",
    "\n",
    "    > df['input'] = 'Text1: ' + df.col1 + ' TEXT2: ' + df.col2 + ' CONTEXT: ' + df.col3\n",
    "\n",
    "    This combined string is then tokenized for model input.\n",
    "\n",
    "2. Splitting the Data: Train, Validation, and Test Sets\n",
    "\n",
    "    * The training set is used to teach the model.\n",
    "    * The validation set helps evaluate and fine-tune the model during training.\n",
    "    * The test set checks how the model performs on completely new data.\n",
    "\n",
    "   Evaluating on test set is like a final performance evaluation.\n",
    "\n",
    "3. Using Pre-trained models\n",
    "\n",
    "    Using pre-trained models (from hugging face) are especially helpful for tasks like comparing pairs of questions. \n",
    "    Because these models have been trained on large volumes of text, they already understand the language structure and can detect subtle differences or similarities in meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "518b4390-6884-4308-9feb-4fa29a2d903a",
    "_uuid": "999fe09b-b0e9-46fa-aa96-613b02c44dab",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3b23724d-c6f8-4f3a-b030-9fd9c49e6c9d",
    "_uuid": "32011a87-8633-4231-b87f-43f7e7b5cb94",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "I have applied some concepts which I learned from the above notebook to the [Question Pairs Dataset](https://www.kaggle.com/datasets/quora/question-pairs-dataset). This dataset contains six columns, as shown below:\n",
    "\n",
    "* **id** - Id for each question pair\n",
    "* **qid1** - Id for question 1 in pair\n",
    "* **qid2** - Id for question 2 in pair\n",
    "* **question1** - Full Text for question 1\n",
    "* **question2** - Full Text for question 2\n",
    "* **is_duplicate** - 1 if duplicate, else 0\n",
    "\n",
    "The target column 'is_duplicate' contains a binary value to indicate if the pair of questions ('question1' and 'question2') represents a duplicate pair or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdafbe44-08c6-4de3-8fb3-4d287089d312",
    "_uuid": "f1dd9c7d-c824-4501-b431-b5630113b97c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Importing Basic Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "360542a4-de4b-4ea1-9a95-ecf1017e6f9c",
    "_uuid": "4856c88e-28a9-4ea8-84f3-97d3cab87759",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "We'll start with importing basic libraries and displaying path to the csv file.\n",
    "\n",
    "* `NumPy` - A Python library for working with arrays and numbers, helps to do math fast with large sets of data like matrices and tables\n",
    "* `Pandas` - A Python library for handling data in tables, makes it easy to read, write, clean and analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a7e89eb-3b06-4809-9fa7-8d9d0f07b3b5",
    "_uuid": "f4b8902d-54c7-4ebb-ae21-bdaaf72ec19a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.459742Z",
     "iopub.status.busy": "2025-07-13T12:34:10.459507Z",
     "iopub.status.idle": "2025-07-13T12:34:10.729236Z",
     "shell.execute_reply": "2025-07-13T12:34:10.728688Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.459719Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee47d448-a405-4504-ab6d-695d506e7a22",
    "_uuid": "f636fd5c-7116-46b5-8835-509946bcef4e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "> As seen in the output above, the input directory contains a sub-directory `question-pairs-dataset`, which contain the dataset file `questions.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7b58f493-fea3-476e-bd69-32019dc1d32b",
    "_uuid": "2e8e67c9-d812-4b28-bdf3-d0ec7500975f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.730069Z",
     "iopub.status.busy": "2025-07-13T12:34:10.729802Z",
     "iopub.status.idle": "2025-07-13T12:34:10.733634Z",
     "shell.execute_reply": "2025-07-13T12:34:10.732959Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.730044Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('../input/question-pairs-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3b1826e8-08c0-4fb0-b9be-8cc31cebc0c5",
    "_uuid": "5342932c-eb4b-4110-9e2e-fdbe7d39a094",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.735158Z",
     "iopub.status.busy": "2025-07-13T12:34:10.734990Z",
     "iopub.status.idle": "2025-07-13T12:34:10.865564Z",
     "shell.execute_reply": "2025-07-13T12:34:10.864945Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.735145Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9042d7b-2b31-4133-834f-04267cda0b9b",
    "_uuid": "45acd109-033c-461f-8398-7447ea6e1551",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "We'll import the CSV file into a `Pandas DataFrame` and, for faster processing, limit it to the first **10,000** rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9ec5dad1-6e97-4870-b0b6-edf4a9276fd0",
    "_uuid": "714a4fd2-e377-49f4-8445-1a9a0215ca50",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.866714Z",
     "iopub.status.busy": "2025-07-13T12:34:10.866509Z",
     "iopub.status.idle": "2025-07-13T12:34:10.925532Z",
     "shell.execute_reply": "2025-07-13T12:34:10.924803Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.866679Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(path/'questions.csv', nrows=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "add24b80-6fb1-4c21-874f-b591c4f84636",
    "_uuid": "4ea16048-ad55-4cb2-854f-cb4a722a348c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b9db23f2-99e6-4778-bb4f-bf9e9f508d41",
    "_uuid": "d61525f7-08b6-4d6d-a30b-04870571ac20",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "We'll removes rows from the DataFrame where `question1` or `question2` has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f36d076d-1cb5-4cb9-9bfd-3c9f56ab72c6",
    "_uuid": "8dcfe5e3-0892-4043-9989-3a30dfb52a15",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.926483Z",
     "iopub.status.busy": "2025-07-13T12:34:10.926280Z",
     "iopub.status.idle": "2025-07-13T12:34:10.942664Z",
     "shell.execute_reply": "2025-07-13T12:34:10.941997Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.926443Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"question1\", \"question2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a0c5d6b-5717-40b0-8aaf-61bd8a79adea",
    "_uuid": "19857773-0714-4f6b-9b89-2b553f90823d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Displaying last **three** rows of the DataFrame for quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eec490bb-5d9a-4e7a-83c1-4e5f9666baa6",
    "_uuid": "7874775a-6c8e-4c24-8ced-86ea57421af2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.943545Z",
     "iopub.status.busy": "2025-07-13T12:34:10.943336Z",
     "iopub.status.idle": "2025-07-13T12:34:10.968064Z",
     "shell.execute_reply": "2025-07-13T12:34:10.967357Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.943529Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "365aef2b-d304-4426-a3dc-5fa7f461851d",
    "_uuid": "43fc998c-abf1-41ca-a682-3bb2a76d7c36",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Displaying `summary statistics` (like **count**, **unique values**, **top value**, and **frequency**) for all object (text/string) in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a3a7c62-bc3e-4fa9-91be-37ff243fc47b",
    "_uuid": "eafcc7e5-4b5d-4513-9a8d-ac9cb824f70b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.969580Z",
     "iopub.status.busy": "2025-07-13T12:34:10.968819Z",
     "iopub.status.idle": "2025-07-13T12:34:10.990719Z",
     "shell.execute_reply": "2025-07-13T12:34:10.989936Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.969557Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0b25ed80-7d4b-4fc3-b4c3-48dd2112977b",
    "_uuid": "d9718874-0ee6-40a8-aa1c-a8774eff730b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "The output above shows that `question1` contains **9,813** unique values, with the most frequent one appearing **4** times. Similarly, `question2` has **9,790** unique values, and its most common value also appears **4** times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1aa71aa7-0a58-4570-b3c0-abd9857eaea9",
    "_uuid": "c36689e8-f617-4ade-a075-e7e0a3fa9216",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "As discussed above, we'll prepare the `input` column by concatenating the two string columns `question1` and `question2` like below-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "55ddb604-2240-4ff8-97e8-82832526917a",
    "_uuid": "f0d549bd-a502-451d-9338-4dd2a80c6370",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:10.991515Z",
     "iopub.status.busy": "2025-07-13T12:34:10.991325Z",
     "iopub.status.idle": "2025-07-13T12:34:11.000180Z",
     "shell.execute_reply": "2025-07-13T12:34:10.999578Z",
     "shell.execute_reply.started": "2025-07-13T12:34:10.991499Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['input'] = 'QUES1: ' + df.question1 + ' QUES2: ' + df.question2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8afdbdc8-a47b-4d2a-8ee6-9e9d312c15a7",
    "_uuid": "688f8162-e31c-4137-a978-6e3e96c4d27e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "This is what our new dataframe looke like with an additional `input` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e9c447e-bffb-41f0-890b-a1e3f47871b7",
    "_uuid": "f688e702-bc25-4542-a0eb-447a39bcc1d8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:11.002928Z",
     "iopub.status.busy": "2025-07-13T12:34:11.002739Z",
     "iopub.status.idle": "2025-07-13T12:34:11.019171Z",
     "shell.execute_reply": "2025-07-13T12:34:11.018645Z",
     "shell.execute_reply.started": "2025-07-13T12:34:11.002913Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98734cc9-9aa8-4d04-a035-d988dccfe702",
    "_uuid": "63e16764-e7a6-4556-b3ea-bcc0ea9a9ff4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f98a4dbd-362f-4b8c-8f21-7188b7e742d0",
    "_uuid": "c915b58f-549b-422f-af8b-7989c16b857b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Converting the `pandas dataframe` into a `hugging face Dataset` to enable efficient data handling for further tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10826d3e-5e81-42f7-8ca0-d5497c84f726",
    "_uuid": "09aec959-0304-4c55-ace6-d7336f916241",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:11.020147Z",
     "iopub.status.busy": "2025-07-13T12:34:11.019943Z",
     "iopub.status.idle": "2025-07-13T12:34:12.354458Z",
     "shell.execute_reply": "2025-07-13T12:34:12.353927Z",
     "shell.execute_reply.started": "2025-07-13T12:34:11.020132Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81cbf570-757f-4cd7-a517-5fe3319e1a81",
    "_uuid": "5b9fe851-91d6-481c-9a5e-5d760945e783",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:12.355408Z",
     "iopub.status.busy": "2025-07-13T12:34:12.355139Z",
     "iopub.status.idle": "2025-07-13T12:34:12.360406Z",
     "shell.execute_reply": "2025-07-13T12:34:12.359606Z",
     "shell.execute_reply.started": "2025-07-13T12:34:12.355393Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "12564c22-f269-48a6-bd3a-d9368b1b2dff",
    "_uuid": "5f26499c-e4d5-4980-8283-e42459d3c65e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Picking a **pre-trained model**, chosen for its efficiency in natural language understanding tasks while being lightweight for faster training, which will be **fine-tuned** later to `predict duplicate pairs` within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8bff77fb-8b6d-4c24-b04f-ba0f142ed153",
    "_uuid": "431a55d1-e689-4432-8131-b1c3dd3f58e2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:12.361435Z",
     "iopub.status.busy": "2025-07-13T12:34:12.361191Z",
     "iopub.status.idle": "2025-07-13T12:34:12.375863Z",
     "shell.execute_reply": "2025-07-13T12:34:12.375187Z",
     "shell.execute_reply.started": "2025-07-13T12:34:12.361413Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading DeBERTa-v3-small model (by Microsoft) from Hugging Face\n",
    "\n",
    "pt_model = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "65c152ea-e89f-4456-925e-3ab4cca07f81",
    "_uuid": "69c77ae6-ce99-43a7-b6af-3527e54de4a6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "**Loading the tokenizer** associated with the pre-trained model, which will `convert text into tokens` suitable for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0eddecdd-132c-41ed-99ef-cac74434a381",
    "_uuid": "0eb97568-f954-4049-9121-bd704b136585",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:12.377200Z",
     "iopub.status.busy": "2025-07-13T12:34:12.376601Z",
     "iopub.status.idle": "2025-07-13T12:34:28.920210Z",
     "shell.execute_reply": "2025-07-13T12:34:28.919656Z",
     "shell.execute_reply.started": "2025-07-13T12:34:12.377179Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tok = AutoTokenizer.from_pretrained(pt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d3e73a0-6369-4a00-8489-04d9320663ad",
    "_uuid": "5f0bc4f0-708b-40a2-8e6d-70f449a1133b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "With below code, we can retrieve he vocabulary index (ID) of an example token `_is` from tokenizer's vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c4e596b-e521-437c-8151-9c3cb6cefdf5",
    "_uuid": "e8fa1b89-5db8-4452-9603-d2683e18867e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:28.921421Z",
     "iopub.status.busy": "2025-07-13T12:34:28.920994Z",
     "iopub.status.idle": "2025-07-13T12:34:28.997676Z",
     "shell.execute_reply": "2025-07-13T12:34:28.996978Z",
     "shell.execute_reply.started": "2025-07-13T12:34:28.921396Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tok.vocab['▁is']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "38880d5f-921a-4b6f-b09e-692700f33d99",
    "_uuid": "4a56e752-4501-4277-93ea-4126949fe9ab",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "`Splitting` an example input sentence into tokens that the model can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c7d5a080-34b1-41f7-81f3-2883a9089ccb",
    "_uuid": "7c83d523-c377-453a-8d74-802f43b64158",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:28.998727Z",
     "iopub.status.busy": "2025-07-13T12:34:28.998432Z",
     "iopub.status.idle": "2025-07-13T12:34:29.014164Z",
     "shell.execute_reply": "2025-07-13T12:34:29.013486Z",
     "shell.execute_reply.started": "2025-07-13T12:34:28.998707Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tok.tokenize('Hello, this is a python program')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4953eae-57e1-41d7-8aea-06617cf505d1",
    "_uuid": "fce3fcbb-7d4e-4480-9a66-b577197461e5",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Defining a function `tok_inp` that takes a dictionary `x` and returns the tokenized verison for the value associated with the `input` key using the tokenizer `tok`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4d28445f-68c3-4bdb-b9bf-68479cdfdef5",
    "_uuid": "7b8a79fb-526b-4f8c-9afa-de6052186e47",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:29.015312Z",
     "iopub.status.busy": "2025-07-13T12:34:29.015027Z",
     "iopub.status.idle": "2025-07-13T12:34:29.024605Z",
     "shell.execute_reply": "2025-07-13T12:34:29.024006Z",
     "shell.execute_reply.started": "2025-07-13T12:34:29.015291Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tok_inp(x): return tok(x[\"input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a0b2c73-e2a2-475e-a04b-1285b3b99ec6",
    "_uuid": "531e2566-2645-4500-a4e2-b27ea8c13989",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "As seen in the output below, there are `no null values`, as they were already handled earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c5cf3ca-3c6f-410b-8ea2-c14c749c89d1",
    "_uuid": "3921ee73-3347-4e92-a995-da15279fb642",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:29.025580Z",
     "iopub.status.busy": "2025-07-13T12:34:29.025310Z",
     "iopub.status.idle": "2025-07-13T12:34:29.042130Z",
     "shell.execute_reply": "2025-07-13T12:34:29.041411Z",
     "shell.execute_reply.started": "2025-07-13T12:34:29.025560Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e220cca-464b-499f-8b3c-a2ee85524b54",
    "_uuid": "5f1e9d60-c972-47bb-aa84-6e693a539953",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:29.043362Z",
     "iopub.status.busy": "2025-07-13T12:34:29.043018Z",
     "iopub.status.idle": "2025-07-13T12:34:29.060106Z",
     "shell.execute_reply": "2025-07-13T12:34:29.059483Z",
     "shell.execute_reply.started": "2025-07-13T12:34:29.043338Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "null_rows = df[df.isnull().any(axis=1)]\n",
    "print(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a149f01-2023-49ce-8b15-c06664e3fd00",
    "_uuid": "e0afc65e-f8a3-4e7a-81a0-03aeacafdc3d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "This line applies the `tok_inp` function to the entire dataset `ds` in batches, creating a new dataset `tok_ds` with tokenized inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d77f990-59e7-480b-984a-69cf20e7fe7c",
    "_uuid": "5237b89e-d296-495d-b810-79a12426ac5e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:29.061424Z",
     "iopub.status.busy": "2025-07-13T12:34:29.060846Z",
     "iopub.status.idle": "2025-07-13T12:34:29.745226Z",
     "shell.execute_reply": "2025-07-13T12:34:29.744667Z",
     "shell.execute_reply.started": "2025-07-13T12:34:29.061401Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tok_ds = ds.map(tok_inp, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2127de5c-0950-48d5-8b18-4ab31670b8b9",
    "_uuid": "49a5828c-d5ca-4782-83c4-152d736706fe",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Applying the tokenization function to the dataset in **batches** adds a new column called `input_ids`, as shown below for the first row of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5de1f959-9a8c-434a-a057-fad92c26f38a",
    "_uuid": "eea0daf5-2240-4208-a840-98da7d1c9922",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:29.746210Z",
     "iopub.status.busy": "2025-07-13T12:34:29.745937Z",
     "iopub.status.idle": "2025-07-13T12:34:29.753219Z",
     "shell.execute_reply": "2025-07-13T12:34:29.752618Z",
     "shell.execute_reply.started": "2025-07-13T12:34:29.746188Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "row = tok_ds[0]\n",
    "row['input'], row['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "525e5b70-8419-4903-8c57-7778780d867c",
    "_uuid": "b067c5b6-d636-4914-9317-a1f7deba2fed",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "> Renaming the column `is_duplicate` to `labels` in the dataset `tok_ds`, preparing it for model training where target values are expected under the name `labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c127b956-5f4a-449c-9a8b-cbf6bdca84c6",
    "_uuid": "76f39217-45dd-44df-9bac-2665083ccb15",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:29.754287Z",
     "iopub.status.busy": "2025-07-13T12:34:29.754013Z",
     "iopub.status.idle": "2025-07-13T12:34:29.766043Z",
     "shell.execute_reply": "2025-07-13T12:34:29.765508Z",
     "shell.execute_reply.started": "2025-07-13T12:34:29.754260Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tok_ds = tok_ds.rename_columns({'is_duplicate':'labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d3268eca-d12d-4c94-8489-e8c760ba239a",
    "_uuid": "bec7396e-3b5f-4821-8065-92d317d430b8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6ab7b7c6-114c-4559-a101-02c99bc34866",
    "_uuid": "488236cc-ab36-458e-b4eb-5dfa33041ac6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "This line creates the **test set** `eval_df` by loading 1,000 separate rows (from index 10,500 to 11,500) from the CSV file, ensuring they are not part of the training or validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "735c6499-2177-4afa-a3ab-223d1b5bc6d2",
    "_uuid": "4f1b7529-8af6-4a36-b553-2543cb7d3d7b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:29.766907Z",
     "iopub.status.busy": "2025-07-13T12:34:29.766660Z",
     "iopub.status.idle": "2025-07-13T12:34:31.340735Z",
     "shell.execute_reply": "2025-07-13T12:34:31.339934Z",
     "shell.execute_reply.started": "2025-07-13T12:34:29.766886Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv(path/'questions.csv').iloc[10500:11500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79723cc2-3e64-4ddb-9709-8734bd7bc829",
    "_uuid": "03325b7e-4229-4946-b4b0-88429b361abf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:31.341811Z",
     "iopub.status.busy": "2025-07-13T12:34:31.341577Z",
     "iopub.status.idle": "2025-07-13T12:34:31.360476Z",
     "shell.execute_reply": "2025-07-13T12:34:31.359917Z",
     "shell.execute_reply.started": "2025-07-13T12:34:31.341794Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dad4acaf-a8c0-4ad3-89fe-8f7148b8ba5c",
    "_uuid": "1cc0d692-db92-4c53-834b-f5c5c72a6e5f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "We'll prepare the input column for the **test set** by concatenating the two string columns `question1` and `question2` like below-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5281283-8e92-4535-a26e-49b6c22f1ab1",
    "_uuid": "e2e00f5a-a2da-44ce-84f8-26c1e9aea2fb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:31.361624Z",
     "iopub.status.busy": "2025-07-13T12:34:31.361321Z",
     "iopub.status.idle": "2025-07-13T12:34:31.467478Z",
     "shell.execute_reply": "2025-07-13T12:34:31.466698Z",
     "shell.execute_reply.started": "2025-07-13T12:34:31.361599Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_df['input'] = 'QUES1: ' + eval_df.question1 + ' QUES2: ' + eval_df.question2\n",
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_inp, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dffeada5-796c-4709-a493-dffe363b0a69",
    "_uuid": "27e21470-73c3-4d0a-a81c-52d93517e83c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "This line splits the tokenized dataset `tok_ds` into a **training set and a validation set**, with **25% used for validation**, using a fixed seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9417e201-dd6a-4f21-a89b-7273ebc11530",
    "_uuid": "0b19fa0b-e8b2-484d-a2c8-4cd3aa4158cb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:31.468675Z",
     "iopub.status.busy": "2025-07-13T12:34:31.468376Z",
     "iopub.status.idle": "2025-07-13T12:34:31.480711Z",
     "shell.execute_reply": "2025-07-13T12:34:31.480127Z",
     "shell.execute_reply.started": "2025-07-13T12:34:31.468652Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dds = tok_ds.train_test_split(0.25, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b299def7-ad89-41e4-a855-0b94ed9362d1",
    "_uuid": "6ff62ac9-585f-4e0c-8ca1-ff1901fff5c4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "In summary, the 10,000-row dataset was split into a **training set** with 7,500 rows and a **validation set** with 2,500 rows. Additionally, a separate **test set** `eval_df` of 1,000 rows was created to ensure it does not overlap with either the training or validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fa4aa373-25cd-49d5-86a1-7b33969c0317",
    "_uuid": "d68930ab-42c0-4ccd-a001-3bae89158e9c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Training our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58e1fbb2-e11a-4650-be7e-7974df693cb4",
    "_uuid": "719f8519-188e-4557-bbc5-ed0a34c97d15",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Defining a function `corr_func` that calculates and returns the **Pearson correlation** between predictions and true labels during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e521f4e8-bfc9-423f-a9a8-c9fba068708d",
    "_uuid": "fa1ac982-1236-46df-9b72-a17633e6a3c5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:31.481751Z",
     "iopub.status.busy": "2025-07-13T12:34:31.481459Z",
     "iopub.status.idle": "2025-07-13T12:34:31.486754Z",
     "shell.execute_reply": "2025-07-13T12:34:31.486184Z",
     "shell.execute_reply.started": "2025-07-13T12:34:31.481736Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def corr_func(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "975dfe12-a897-474b-9fae-c95977fa72aa",
    "_uuid": "58a056fd-f240-4c63-ab59-9f3f61de4a36",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:31.490333Z",
     "iopub.status.busy": "2025-07-13T12:34:31.489775Z",
     "iopub.status.idle": "2025-07-13T12:34:45.229045Z",
     "shell.execute_reply": "2025-07-13T12:34:45.228496Z",
     "shell.execute_reply.started": "2025-07-13T12:34:31.490318Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2d6721c-b32a-41d0-9061-82b148b9b6d6",
    "_uuid": "73ee8e2a-0149-42fb-bab2-eeb8f2975348",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Setting up training configuration, specifying **parameters** like `learning rate`, `batch size`, `number of epochs`, and more. \n",
    "Note: larger batch sizes may exceed available GPU memory and lead to out-of-memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ef40f975-1177-40f8-9215-862a9274f452",
    "_uuid": "f7893bee-b6ca-4daf-a4aa-0afe03917777",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:45.230305Z",
     "iopub.status.busy": "2025-07-13T12:34:45.229725Z",
     "iopub.status.idle": "2025-07-13T12:34:45.233787Z",
     "shell.execute_reply": "2025-07-13T12:34:45.233130Z",
     "shell.execute_reply.started": "2025-07-13T12:34:45.230275Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bs = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b408c955-cbf9-4ca3-9c73-405fd61ff46c",
    "_uuid": "7c8d8645-ab5b-4fdb-b79d-7858ca79eca4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:45.234893Z",
     "iopub.status.busy": "2025-07-13T12:34:45.234627Z",
     "iopub.status.idle": "2025-07-13T12:34:45.269981Z",
     "shell.execute_reply": "2025-07-13T12:34:45.269310Z",
     "shell.execute_reply.started": "2025-07-13T12:34:45.234870Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e8a2a25-4364-410f-8a38-050e22575cc3",
    "_uuid": "1b41a88c-1e89-4678-87ad-e87f6d4cbfae",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:45.270864Z",
     "iopub.status.busy": "2025-07-13T12:34:45.270662Z",
     "iopub.status.idle": "2025-07-13T12:34:45.310921Z",
     "shell.execute_reply": "2025-07-13T12:34:45.310431Z",
     "shell.execute_reply.started": "2025-07-13T12:34:45.270843Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    'outputs', \n",
    "    learning_rate=lr,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6b45268a-9d02-4461-910e-a96bb094293f",
    "_uuid": "1c569996-6fac-419c-9dde-e193046999a2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Loading a pre-trained model for sequence classification with 2 labels, setting up a `Trainer` using the specified training/validation sets and metrics, then fine-tuning the model with `trainer.train()`.\n",
    "NOTE: In the below code, *dds['train']* represents the `training set` and *dds['test']* represents the `validation set`, we'll be evaluating the model on the `test set` *eval_ds* later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2414c6ee-1964-4f82-94f0-725dacbd1293",
    "_uuid": "cc0c757c-11d5-42d6-9fcd-ab4d1b62ef1a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:45.311717Z",
     "iopub.status.busy": "2025-07-13T12:34:45.311527Z",
     "iopub.status.idle": "2025-07-13T12:34:54.218034Z",
     "shell.execute_reply": "2025-07-13T12:34:54.217499Z",
     "shell.execute_reply.started": "2025-07-13T12:34:45.311703Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(pt_model, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dds['train'],\n",
    "    eval_dataset=dds['test'],\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=corr_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f95adf5-e630-41b1-8284-be96266874d1",
    "_uuid": "1446735b-95dc-4bd5-8287-adbd90c9aaa5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:34:54.219063Z",
     "iopub.status.busy": "2025-07-13T12:34:54.218802Z",
     "iopub.status.idle": "2025-07-13T12:37:37.190373Z",
     "shell.execute_reply": "2025-07-13T12:37:37.189798Z",
     "shell.execute_reply.started": "2025-07-13T12:34:54.219041Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ba3bd2b3-b9e0-4b72-871f-6450ff82136f",
    "_uuid": "724b042f-26c6-4d29-b959-13f46f3df47d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Evaluating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af05e55b-f451-42c3-9938-d4546b6874ba",
    "_uuid": "97d6baec-55ec-4b67-8fbf-ac748d311995",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Using the trained model to make predictions on the **test set** `eval_ds`, extracting the output scores (`logits`), and selecting the class with the highest score as the final predicted label for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00aa90ca-174f-4ed4-99b1-f81927be1611",
    "_uuid": "4ebab944-7528-4d84-bbc9-619ea832caa7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:51:52.013850Z",
     "iopub.status.busy": "2025-07-13T12:51:52.013562Z",
     "iopub.status.idle": "2025-07-13T12:51:52.019121Z",
     "shell.execute_reply": "2025-07-13T12:51:52.018394Z",
     "shell.execute_reply.started": "2025-07-13T12:51:52.013832Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(eval_ds)\n",
    "logits = predictions.predictions\n",
    "predicted_labels = np.argmax(logits, axis=1)\n",
    "predicted_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cbf5fc7-77f0-4c80-89d5-478e64464352",
    "_uuid": "d7ed21d9-003b-411d-971f-6e99dd4cbb59",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "After predicting labels for the test set, we'll **review a few sample predictions** before calculating the overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "354d43be-8c87-43d6-b416-6725110027b3",
    "_uuid": "37579fa5-e753-4abb-bf51-867cbcbc993b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "The predicted label for index 1 in the test set is 0, indicating that the pair of questions is **not a duplicate** — which is supported by the input questions shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9f9a9c0b-d57d-43ab-b370-517c4e254e2a",
    "_uuid": "351b9d70-878f-4772-8208-c5834df5cb60",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:37:39.398288Z",
     "iopub.status.busy": "2025-07-13T12:37:39.397998Z",
     "iopub.status.idle": "2025-07-13T12:37:39.402538Z",
     "shell.execute_reply": "2025-07-13T12:37:39.401946Z",
     "shell.execute_reply.started": "2025-07-13T12:37:39.398264Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(eval_df['input'].iloc[1]),\n",
    "print(\"(Duplicate Pair)\" if predicted_labels[1] == 1 else \"(Not a duplicate pair)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e3b00de7-ef42-48cd-b7c4-d7c6007ff033",
    "_uuid": "cec00b87-1f53-4146-8b4f-d7b6ebc73b79",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Similarly, the predicted label for index 2 in the test set is 1, indicating that the pair of questions is considered a **duplicate** — as supported by the input questions shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c5d3004e-6337-49e2-a037-137c5ed1d4e4",
    "_uuid": "564a0b81-75bf-4e05-843e-a1985284c34e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:37:39.403437Z",
     "iopub.status.busy": "2025-07-13T12:37:39.403219Z",
     "iopub.status.idle": "2025-07-13T12:37:39.417425Z",
     "shell.execute_reply": "2025-07-13T12:37:39.416788Z",
     "shell.execute_reply.started": "2025-07-13T12:37:39.403415Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(eval_df['input'].iloc[2]),\n",
    "print(\"(Duplicate Pair)\" if predicted_labels[2] == 1 else \"(Not a duplicate pair)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c6c6152-5a18-4961-b79d-c64f72445f0a",
    "_uuid": "289d4ecf-9cf6-49a4-b028-7cee7650e8b0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "The first `10 actual label values` from the test set are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9e4ce49-e1bd-46f5-bce6-00fa2df495dd",
    "_uuid": "a9afef06-616c-4ea6-8f37-1652455aaf2f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:53:23.593350Z",
     "iopub.status.busy": "2025-07-13T12:53:23.593051Z",
     "iopub.status.idle": "2025-07-13T12:53:23.597908Z",
     "shell.execute_reply": "2025-07-13T12:53:23.597204Z",
     "shell.execute_reply.started": "2025-07-13T12:53:23.593332Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(eval_df['is_duplicate'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d065c12-f456-402f-ba7f-8ce4ea3fc21d",
    "_uuid": "cdaa2120-fee5-444a-9bfd-126452276feb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Calculates and prints the `accuracy` of the model’s **predicted labels** against the **true labels** from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a85c96d8-3bcd-4343-a328-8698bb782efb",
    "_uuid": "35ddbdb1-fc88-49c3-bbf9-a2d901d2808d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-13T12:49:28.609908Z",
     "iopub.status.busy": "2025-07-13T12:49:28.609641Z",
     "iopub.status.idle": "2025-07-13T12:49:28.616354Z",
     "shell.execute_reply": "2025-07-13T12:49:28.615675Z",
     "shell.execute_reply.started": "2025-07-13T12:49:28.609891Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(eval_df['is_duplicate'], predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 747,
     "sourceId": 1423,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
